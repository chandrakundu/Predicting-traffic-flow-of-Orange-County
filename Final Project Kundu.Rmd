---
title: "Prediting traffic flow of Orange County"
subtitle: "STA:5104 Final Project"
author: "Chandra Kundu"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
    collapsed: false
    smooth_scroll: false
    number_sections: true
    theme: readable
    highlight: pygments
    df_print: paged
    code_folding: hide
    bibliography: references.bib
---

# Overview and Motivation
For intelligent transportation systems (ITS), it is necessary to have information about the actual and near-future traffic volume. That is why traffic volume prediction is a critical element of traffic flow management and operation. The transport authorities can use the insights from traffic volume prediction to avoid congestion on roadways. For everyday drivers, real-time estimates of traffic flow can provide knowledge and direction to enhance their travel experience and reduce costs. 

On daily traffic, the weather may have an impact on travel time and traffic flow. Especially, inclement weather can significantly degrade roadway traffic operations. Traffic flow is also dependent on the day of a week, that is, if the day is a weekend, holiday, or weekday and which part of the day it is.  Moreover, we saw a large drop in traffic volume after the start of the COVID-19 lockdown.  In this project, I will use linear regression and random forest to estimate future traffic flow based on weather conditions in Orange county Florida. I also incorporate the effect of the pandemic on traffic volume. 

# Related Work
Due to the importance of traffic flow prediction in urban traffic optimization, predicting traffic flow is a very popular topic across academia. A lot of work has been done since the last century.  Some of the important approaches were proposed using series models [^Billy] [^Said] [^Moorthy], Kalman filter theory [^Iwao], Markov chain model [^Guoqiang], non-parametric methods [^Oswald], Bayesian networks [^Enrique], etc.  Moreover, in recent years, people are using deep learning to predict the traffic flow [^Lv] [^Tedjopurnomo]. 

For this project, I am mostly inspired by the work done on Metro Interstate Traffic Volume Data Set[^metro] [^manoj] [^ramyahr] [^simonwenkel]. 

# Initial Questions
Through this project, I seek to answer four primary questions:

* How do weather variables affect the traffic volume of Orange county?
* How do Covid-19 affect the traffic volume of Orange county?
* What is the effect of different holidays and different part of the day on the traffic volume of Orange county?
* How we can use the variable to predict the traffic volume of Orange county?

# Data
The hourly volume of traffic of orange county has been scrapped from the website of the Florida Department of Transportation[^fdot]. Due to the unavailability, data from January 01, 2020 to July 08, 2020 has been collected.  The weather data has been bought from the VisualCrossing[^visualcrossing]. Moreover, the traffic volume may be depended on the holidays and weekends. The data for holidays has also been collected[^holiday] and put in a csv file. 


> **_NOTES on Code:_**  <p style="font-size:11pt; font-style:italic"> By default, I hide the code. However, the code can be seen by pressing the ```Code``` button. In addition, I just showed neccessary the result that is important for the data analysis. </p>

## Data Wrangling
In this section, we are going to do the following tasks.

* Clean weather data
* Clean traffic data
* Merge the weather data and traffic data
* Incorporate the data with holiday, weekend and lockdown


```{r package-options, results='hide', message=FALSE, warning=FALSE}
library(rmarkdown)
library(tidyverse)
library(lubridate) # manipulate date and time
library(scales) # for scaling datetime in ggplot
library(patchwork) # for vertical plots
library(corrplot)
library(randomForest)
library(e1071)
```

### Weather Data
```{r, results='hide', message=FALSE, warning=FALSE}
weather_original <- read_csv("data/weather/weather-orange.csv") 
```

```{r}
head(weather_original)
```


Here, I found that a lot a missing value in the windchill, heatindex and snowdepth columns. So I drop these column. Moreover, the categorical variable "conditions" is actually an aggregated value of the numerical variable rain and cloud. So I also drop this column. In addition, datetime has been read as <chr> which I convert into <dtt> format. 

```{r}
weather <- weather_original %>%
  select(datetime, temp, rain, windspeed, visibility:relhumidity) %>%
  mutate_at(vars(datetime), ~strptime(.,format='%m/%d/%Y %H:%M:%S')) 
head(weather)
```


Now I check if there is any missing value in the weather data. 
```{r}
colSums(is.na(weather))
```


Since there is only a few missing value, I drop these rows and display the summary and time-series visaulization of weather data. 
```{r}
weather <- na.omit(weather)
summary(weather)
```

```{r fig.width=7, fig.height=15}
p1 <- weather %>%
  ggplot(aes(x=ymd_hms(datetime), y=temp)) +
  geom_line(color="gold") +
  labs(x = "Time", y = "Temperature (°F)") + 
  scale_x_datetime(labels = date_format("%d-%m\n%H:%M"), expand = c(0, 0),) + 
  ggtitle("Hourly Temperature Data")
p2 <- weather %>%
  ggplot(aes(x=ymd_hms(datetime), y=rain)) +
  geom_line(color="navy") +
  labs(x = "Time", y = "Rain") + 
  scale_x_datetime(labels = date_format("%d-%m\n%H:%M"), expand = c(0, 0),) + 
  ggtitle("Hourly Rain Data")
p3 <- weather %>%
  ggplot(aes(x=ymd_hms(datetime), y=windspeed)) +
  geom_line(color="maroon") +
  labs(x = "Time", y = "Windspeed") + 
  scale_x_datetime(labels = date_format("%d-%m\n%H:%M"), expand = c(0, 0),) + 
  ggtitle("Hourly Windspeed Data")

p4 <- weather %>%
  ggplot(aes(x=ymd_hms(datetime), y=visibility)) +
  geom_line(color="purple") +
  labs(x = "Time", y = "Visibility") + 
  scale_x_datetime(labels = date_format("%d-%m\n%H:%M"), expand = c(0, 0),) + 
  ggtitle("Hourly Visibility Data")

p5 <- weather %>%
  ggplot(aes(x=ymd_hms(datetime), y=cloudcover)) +
  geom_line(color="steelblue") +
  labs(x = "Time", y = "Cloudcover") + 
  scale_x_datetime(labels = date_format("%d-%m\n%H:%M"), expand = c(0, 0),) + 
  ggtitle("Hourly cloudcover Data")

p6 <- weather %>%
  ggplot(aes(x=ymd_hms(datetime), y=relhumidity)) +
  geom_line(color="lightblue") +
  labs(x = "Time", y = "Relative Humidity") + 
  scale_x_datetime(labels = date_format("%d-%m\n%H:%M"), expand = c(0, 0),) + 
  ggtitle("Hourly Relative Humidity Data")

p1/p2/p3/p4/p5/p6

```

### Traffic Data
```{r, results='hide', message=FALSE, warning=FALSE}
traffic_original <- 
    list.files(path = "data/traffic", pattern = "*.csv", full.names = T) %>% 
    map_df(~read_csv(., col_types = cols(.default = "c")))
```

From the data description, I know the Orange county code is 75. I filter the traffic data for Orange county and convert the datetime into necessary format. I also select the necessary columns. 

```{r}
traffic <- traffic_original %>%
    filter(COUNTY == "75") %>% 
    select(BEGDATE:HR24, -DIR) %>%
    mutate_at(vars(BEGDATE), ~as.Date(., format= "%m/%d/%Y"))

names(traffic) <- tolower(names(traffic))
head(traffic)
```

Now, I add weekend and holidays to traffic data. 
```{r, results='hide', message=FALSE, warning=FALSE}
holiday <- read_csv("data/holiday_list.csv")
holiday$date <- as.Date(holiday$date, format= "%m/%d/%Y")
```

```{r}
holiday

```


```{r}
traffic <- traffic %>%
    mutate(holiday = weekdays(begdate)) %>% 
    mutate_at(vars(holiday), ~recode(., Saturday=1, Sunday=1, .default = 0 )) %>%
    left_join(holiday, by = c("begdate"= "date")) %>%
    mutate(holiday = ifelse(!is.na(day_int), 1, holiday)) %>%
    select(-day_int, -holiday_name)

head(traffic)

```

The data is not in a tidy format. Now I make a tidy data from it and drop missing values. 
```{r , message=FALSE, warning=FALSE}
# hours hr1 to hr24
hours <- map_chr(1:24, ~paste0("hr", .x))

# pivote hour row to column
# change the variable name
traffic <- traffic %>%
    pivot_longer(hr1:hr24, names_to = "time", values_to = "volume") %>%
    mutate_at(vars(time), ~as.numeric(factor(., hours, 1:24))) %>%
    unite("datetime", c("begdate", "time"), sep = "T") %>%
    mutate(datetime = ymd_h(datetime, tz="America/New_York")) %>%
    arrange(datetime)

# convert into numeric volume
traffic$volume <- as.numeric(traffic$volume)  

# drop missing values 
traffic <- na.omit(traffic)


# aggregate traffic volume for all site in one hour
traffic <- traffic %>% 
    group_by(datetime) %>%
    summarise(volume =sum(volume), holiday = mean(holiday))

sample_n(traffic, 10)

```

Now, visualize the traffic volume vs time. 
```{r}
traffic %>%
  ggplot(aes(x=ymd_hms(datetime), y=volume)) +
  geom_line() +
  labs(x = "Time", y = "Traffic Volume") + 
  scale_x_datetime(labels = date_format("%d-%m\n%H:%M"), expand = c(0, 0),) + 
  ggtitle("Hourly Traffic Volume Data") + 
  geom_vline(xintercept = as.numeric(as_datetime("2020-03-13")), linetype="dashed", 
                color = "red", size=1.5)
```

We see a drop in traffic after March 15, 2020. Because, on March 13, President Donald Trump declared a U.S. national emergency and later on March 15, the CDC issued guidance recommending against any gathering of 50 [^4]. We make a column called corona to include this issue into our data. 
```{r}
traffic <- traffic %>%
    mutate(corona = ifelse(datetime <= as.Date('2020-03-15'),0,1))
```

Moreover, there are possible outliers in the  data. I use a boxplot to check it. 
```{r}
traffic %>%
    ggplot(aes(y=volume)) + 
    geom_boxplot(outlier.colour="red", outlier.shape=8,
                outlier.size=4)
```

Now, I remove those outliers. 
```{r}
upper <- quantile(traffic$volume, 0.75, na.rm = T) + 1.5*IQR(traffic$volume, na.rm = T)
traffic$volume[traffic$volume > upper] <- NA
traffic <- na.omit(traffic)
summary(traffic)
```


```{r}
traffic %>%
  filter(datetime >= as.Date('2020-01-06') & datetime <= as.Date('2020-01-08')) %>%
  ggplot(aes(x=ymd_hms(datetime), y=volume)) +
  geom_line() +
  labs(x = "Hour", y = "Traffic Volume") + 
  scale_x_datetime(labels = date_format("%H:%M"), breaks = "4 hour") + 
  ggtitle("Hourly Traffic Volume Data For Two Days")
```

From the plot of two day traffic, each part of the day has different traffic volume. To address this issue, I divide the whole 24 hours into 6 groups. They are Dawn (02.00 — 05.59), Morning (06.00 —09.59), Noon (10.00–13.59), Afternoon (14.00–17.59), Evening (18.00–21.59), and Midnight (22.00–01.59 on Day+1). 
```{r}
get_daypart <- function(hr){
    daypart<- "midnight"
    if (hr %in% 2:5) {
        daypart <- "dawn"
    } else if (hr %in% 6:9) {
        daypart <- "morning"
    }else if (hr %in% 10:13) {
        daypart <- "noon"
    }else if (hr %in% 14:17) {
        daypart <- "afternoon"
    }else if (hr %in% 18:21) {
        daypart <- "evening"
    }
    daypart
}

traffic$daypart <- sapply(hour(traffic$datetime), get_daypart)
```

Now I merge the weather and traffic data. 
```{r}
volume_by_daypart <- full_join(weather, traffic, by = "datetime") 
```

Now I check if there is any missing value in the merged data and drop the missing values. 

```{r}
volume_by_daypart <- na.omit(volume_by_daypart)
head(volume_by_daypart)
```
# Exploratory Analysis

Before designing the prediction model, I analyze the collected data to discover some interesting findings that we would then explore further. First I do some univariate analysis. To do that, first I standardize the predictor variables so that they have a mean of 0 and standard deviation of 1. It is easier to compare if the estimated coefficients are all on the same scale. 

```{r}
df <- volume_by_daypart %>% select(-datetime)
df$temp <- scale(df$temp)
df$rain <- scale(df$rain)
df$windspeed <- scale(df$windspeed)
df$visibility <- scale(df$visibility)
df$cloudcover <- scale(df$cloudcover)
df$relhumidity <- scale(df$relhumidity)
```

```{r}
hist(df$volume,  
     main="Histogram for Traffic Volume (Predicted Variable)", 
     xlab="Traffic Volume",prob = TRUE,  border="black", col="peachpuff")
d <- density(df$volume) # returns the density data
#lines(d, col="peachpuff") # plots the results
polygon(d, col=rgb(1, 0, 0,0.3), border = "black")
abline(v=median(df$volume),col="red")
```

```{r}
par(mfrow=c(3,2))
hist(df$temp,  
     main="Histogram for Temperature", 
     xlab="Temperature",  border="black", col="lightblue")
abline(v=median(df$temp),col="red")

hist(df$rain,  
     main="Histogram for Rain", 
     xlab="Rain",  border="black" ,col="green")
abline(v=median(df$rain),col="red")
hist(df$windspeed,  
     main="Histogram for windspeed", 
     xlab="windspeed",  border="black", col="purple")
abline(v=median(df$windspeed),col="red")
hist(df$visibility,  
     main="Histogram for visibility", 
     xlab="visibility",  border="black", col="navy")
abline(v=median(df$visibility),col="red")
hist(df$cloudcover,  
     main="Histogram for cloudcover", 
     xlab="cloudcover",  border="black", col="yellow")
abline(v=median(df$cloudcover),col="red")
hist(df$relhumidity,  
     main="Histogram for reletive humidity", 
     xlab="reletive humidity",  border="black", col="maroon")
abline(v=median(df$relhumidity),col="red")

```

Let's look ate correlation between numerical variables
```{r}
df %>%
  select(temp:volume) %>%
  cor() %>%
  corrplot(method="number")
```

```{r}
par(mfrow=c(1,2))
boxplot(volume~holiday, data=df, main='Traffic Volume vs. Holidays and Weekend',
        xlab='Holidays and Weekend (1 for Yes)',
        ylab='Traffic Volume', 
        col=(c("gold","darkgreen")))
boxplot(volume~corona, data=df, main='Traffic Volume vs. Covid-19 Lockdown',
        xlab='Covid-19 Lockdown (1 for Yes)', ylab='Traffic Volume',
        col=(c("purple","lightblue")))
par(mfrow=c(1,1))
boxplot(volume~daypart, data=df, main='Traffic Volume vs. Part of the Day',
        xlab='Part of the Day', ylab='Traffic Volume',
        col=(c("gold","darkgreen","purple", "steelblue", "maroon")) )
```

Now, to do bivariate analysis, draw volume vs predictor variable scatter plot. 

```{r}
p1 <- df %>%
  ggplot(aes(x=temp, y=volume)) +
  geom_point(color="skyblue") +
  labs(x = "Temperature (°F)", y = "Volume") + 
  ggtitle("Temperature vs Volume")

p2 <- df %>%
  ggplot(aes(x=rain, y=volume)) +
  geom_point(color="green") +
  labs(x = "Rain", y = "Volume") + 
  ggtitle("Rain vs Volume")

p3 <- df %>%
  ggplot(aes(x=windspeed, y=volume)) +
  geom_point(color="purple") +
  labs(x = "Windspeed", y = "Volume") + 
  ggtitle("Windspeed vs Volume")

p4 <- df %>%
  ggplot(aes(x=visibility, y=volume)) +
  geom_point(color="navy") +
  labs(x = "Visibility", y = "Volume") + 
  ggtitle("Visibility vs Volume")

p5 <- df %>%
  ggplot(aes(x=cloudcover, y=volume)) +
  geom_point(color="yellow") +
  labs(x = "Cloudcover", y = "Volume") + 
  ggtitle("Cloudcover vs Volume")

p6 <- df %>%
  ggplot(aes(x=relhumidity, y=volume)) +
  geom_point(color="maroon") +
  labs(x = "Relative Humidity", y = "Volume") + 
  ggtitle("Relative Humidity vs Volume")

(p1+p2)/ (p3 + p4)/(p5+p6)

```


## Finding
Here is my findings from the exploratory analysis:

* Traffic volume is slightly positive correlated to temperature. 
* It seems there is no corelation between volume and rain, volume and cloudcover, volume and visibility. 
* From the correlation plot and scatter plot, we see there is a negative correlaton between relative humidity and volume. 
* We do not see any non-linear relationship between dependent and any of the predictor variables. 
* From the correlation plot, we do not see any significant multicolinearity. 
* From the look of boxplot of volume based on different categorical variables, it seems there is relation between volume and these categorical variables. 


# The Prediction model
For the prediction model, I divide the data into two part: 90% training data and 10% test data. After fitting model, I will compare the results using r-squared and root-mean-squared-error (RMSE) value. 

```{r}
set.seed(101)
test_id <- sample(seq_len(nrow(df)), size = 0.1*nrow(df))
df_test <- df[test_id, ]
df_train <- df[-test_id, ]
```

## The Linear Regression

For linear regression, I use backwards elimination for model selection. Here, I start with a model with all possible predictors included, and then I will drop variables one at a time until a parsimonious model is reached. During the process, I focus on p values and adjusted R squared.

```{r}
model <- lm(volume~temp+rain+windspeed+visibility+cloudcover
            +relhumidity+holiday+corona+daypart, data = df_train)
summary(model)
```

Here, I found that windspeed has the highest p-value. I drop this predictor. 

```{r}
model <- lm(volume~temp+rain+visibility+cloudcover
            +relhumidity+holiday+corona+daypart, data = df_train)
summary(model)
```

Here, I found that cloudcover has the highest p-value. I drop this predictor. 
```{r}
model <- lm(volume~temp+rain+visibility+
            relhumidity+holiday+corona+daypart, data = df_train)
summary(model)
```
Now, I drop the predictor visibility which has the highest p-value. 
```{r}
model <- lm(volume~temp+rain+
            +relhumidity+holiday+corona+daypart, data = df_train)
summary(model)
```
Now I pring out coefficients of the final model. 
```{r}
reg_coef <- coefficients(model)
reg_coef
```

Now I see every predictor is significant here. I choose this model as my final model. I will do some goodness of fit of this model. 



```{r}
p1<-ggplot(data = model, aes(x = .fitted, y = .resid)) +
  geom_point(color="red") +
  geom_hline(yintercept = 0, linetype = "dashed") +
  xlab("Fitted values") +
  ylab("Residuals")+  ggtitle('(A) Residuals vs Fitted Value')


p2<-ggplot(data = model, aes(sample = .resid)) +
  stat_qq()+  ggtitle('(B) Sample vs theoretical')

residuals = resid(model)
p3<-ggplot(data.frame(residuals), aes(x = residuals))+
    geom_histogram(fill="gold", color="black")
           


(p1 + p2) / p3
```

From Figure A, I found a quasi homoscedasticity. The figure B shows that the residual plot is overall normal. Moreover, the figure C shows normal distribution of residuals round zero.

### Prediction
Now I make a prediction interval for the test data and compare with the actual result. 
```{r}
df_test2 <- df_test %>% 
  select( -windspeed, -visibility, -cloudcover, -volume)
pred <- as_tibble(predict(model, df_test2, interval = "prediction", level = 0.95))
pred$exact <- df_test$volume
pred
```

We see that most of the exact values are in the 95% confidence interval. Now find the R-squared and RMSE value. 

```{r}
rg_res <- data.frame(
  rmse = mean((pred$exact - pred$fit)^2) %>% sqrt(),
  rsq = cor(pred$exact,pred$fit)^2
  )
rg_res
```


## Random Forest
For random forest, I use the same training and testing data. Since I have 9 predictors, I will choose 3 variables randomly sampled as candidates at each split. I run a for loop to find the best number of trees to grow. 

```{r}
ntree <- seq(10, 300, by=30)
res <- data.frame()
for (n in ntree) {
  set.seed(100)
  model <- randomForest(volume ~ ., data = df_train, ntree=n)
  pred <- predict(model, df_test)
  rmse <- mean((pred - df_test$volume)^2) %>% sqrt()
  rsq <- cor(pred,df_test$volume)^2
  new_res <- data.frame(ntree=n, rmse=rmse, rsq=rsq)
  res <- rbind(res, new_res)
}
res
```
. 
I found the best number of trees to grow is 220 I will use this as my final model. 


```{r}
set.seed(100)
model <- randomForest(volume ~ ., data = df_train, ntree=70, importance=T)
pred <- predict(model, df_test)
pred_exact<- data.frame(pred=pred, exact=df_test$volume)
rmse <- mean((pred - df_test$volume)^2) %>% sqrt()
rsq <- cor(pred,df_test$volume)^2

rf_res <- data.frame(rmse, rsq)
rf_res
```


### Variable Importance

```{r}
varImpPlot(model, main = "Variable Importance Plot")

```
The plot shows that for both "Mean Decrease Accuracy" and "Mean Decrease Gini", cloudcover, rain and visibility are the least important variables. The final model predicted rmse = 3157.767 and predicted r-squared = 0.8720748		

```{r}
ggplot(data = pred_exact, aes(x = pred, y = exact)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  xlab("Fitted values") +
  ylab("Exact Value")+  ggtitle(' Exact Value vs Fitted Value')
```

## Final Analysis
```{r}
rbind(rg_res, rf_res)
reg_coef
```
The first row is the result for regression and the second row is for random forest. From the regression analysis, we see temperature, rain and relative humidity has significant impact on the Orange county traffic volume. However, in random forest variance importance plot, we see the rain variable is less significant. For both model, daypart is an important factor. Instead of group the day 6 part, we can use the whole 24 groups to predict the traffic volume for each hour. That would be more accurate. 

Moreover, from regression, we see Covid-19 lockdown had a significant effect on the Orange county traffic volume. If we keep the other variables same, for corona, there is a decrease of 8156 vehicle. Holiday and weekend has also an impact on trafic flow. If we keep the other variables same, there is a decrese of 1941 vehicles in holiday and weekend. 

Though random forest has highest R-squared value and lowest RMSE value, the regression model best describes the relation with the variable. 


# Conclusion
In this project, I collected real data to analyze the Orange county traffic flow. First, I cleaned the data and explored the data to find important facts about the Orange county traffic. Then I fit two models: linear regression and random forest. In terms of R-squared and RMSE, random forest is better than Regression. However, from regression, we can determine the effect of each predictor on the traffic data. To accuratly model the Orange county traffic flow, more data needs to be collected. Furthermore, more complex model rather than linear regression and random forest can be used to predict the traffic volume of Orange county. 




# References

[^fdot]: https://www.fdot.gov/statistics/trafficdata/default.shtm
[^visualcrossing]: https://www.visualcrossing.com/
[^holiday]: https://www.officeholidays.com/countries/usa/florida/2020
[^4]: https://abcnews.go.com/Health/timeline-coronavirus-started/story?id=69435165

[^Billy]: M.ASCE Billy M. Williams and F.ASCE Lester A. Hoel. Modeling and forecasting vehicular traffic flow as a seasonal arima process: Theoretical basis and empirical results. Journal of Transportation Engineering, 129(6):664–672, November 2003.

[^Said]:Z.M.B. Said M.M. Hamed, H.R. Al-Masaeid. Short-term prediction of traffic volume in urban arterials. Journal
of Transportation Engineering, pages 249–254, 1995.

[^Moorthy]: C. K. Moorthy and B. G. Ratcliffe. Short term traffic forecasting using time series methods. Transportation
Planning and Technology, 12(1):45–56, 1988.

[^Iwao]: Iwao Okutani and Yorgos J. Stephanedes. Dynamic prediction of traffic volume through kalman filtering theory.
Transportation Research Part B: Methodological, 18(1):1 – 11, 1984.

[^Guoqiang]: Guoqiang Yu, Jianming Hu, Changshui Zhang, Like Zhuang, and Jingyan Song. Short-term traffic flow forecasting based on markov chain model. In Intelligent Vehicles Symposium, 2003. Proceedings. IEEE, pages 208 – 212, june 2003.

[^Oswald]: R.K. Oswald B.L. Smith, B.M. Williams. Parametric and nonparametric traffic volume forecasting. Paper
Presented at the 2000 Transportation Research Board Annual Meeting, Washington, DC, 2000.

[^Enrique]: Enrique Castillo, Jos Mara Menndez, and Santos Snchez-Cambronero. Predicting traffic flow using bayesian
networks. Transportation Research Part B: Methodological, 42(5):482 – 509, 2008

[^Lv]: Lv Y, Duan Y, Kang W, Li Z, Wang FY. Traffic flow prediction with big data: a deep learning approach. IEEE Transactions on Intelligent Transportation Systems. 2014 Sep 9;16(2):865-73.

[^Tedjopurnomo]: Tedjopurnomo DA, Bao Z, Zheng B, Choudhury F, Qin AK. A Survey on Modern Deep Neural Network for Traffic Prediction: Trends, Methods and Challenges. IEEE Transactions on Knowledge and Data Engineering. 2020 Jun 9.

[^metro]: https://archive.ics.uci.edu/ml/datasets/Metro+Interstate+Traffic+Volume
[^manoj]: https://github.com/ManojKumarMaruthi/Regression
[^ramyahr]: https://www.kaggle.com/ramyahr/metro-interstate-traffic-volume
[^simonwenkel]: https://www.simonwenkel.com/2019/06/20/revisitingML-Metro-Interstate-Traffic_volume.html
